#structure of data files

#import data from http://skeezix.wallednetworks.com:13001/links_1 
http://pythonadventures.wordpress.com/2011/03/10/extract-all-links-from-a-web-page/
#convert scoreboard into json
#import all linked data (using https://github.com/eventlet/eventlet)
#looks like 

#urls = ["http://www.google.com/intl/en_ALL/images/logo.gif",
#     "https://wiki.secondlife.com/w/images/secondlife.jpg",
#     "http://us.i1.yimg.com/us.yimg.com/i/ww/beta/y3.gif"]

#import eventlet
#from eventlet.green import urllib2  

#def fetch(url):
#  body = urllib2.urlopen(url).read()
#  return url, body

#pool = eventlet.GreenPool()
#for url, body in pool.imap(fetch, urls):
#  print "got body from", url, "of length", len(body)

#make local copy of data / database? sqllite
http://stackoverflow.com/questions/8811783/convert-json-to-sqlite-in-python-how-to-map-json-keys-to-database-columns-prop

#function to load sqldata into json object
#load new json 

#find certain name in each database
#find is there was a change for that name from previous to new version (position / new high scores)
#parsing values http://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file-in-python
